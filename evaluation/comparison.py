import os
import sys
import numpy as np
import matplotlib.pyplot as plt
import torch
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import json
import tabm
from tabm import EnsembleView
import joblib
import rtdl_num_embeddings
# =====================================================================
# 1. ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Path ‡πÅ‡∏•‡∏∞ System Environment
# =====================================================================
# ‡∏´‡∏≤‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á Root ‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå (‡∏ñ‡∏≠‡∏¢‡∏à‡∏≤‡∏Å evaluation/ ‡πÑ‡∏õ 1 ‡∏ä‡∏±‡πâ‡∏ô)
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(CURRENT_DIR)

if PROJECT_ROOT not in sys.path:
    sys.path.append(PROJECT_ROOT)

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Device (‡πÉ‡∏ä‡πâ GPU ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ä‡πâ CPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# =====================================================================
# 2. Import ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏à‡∏£‡∏¥‡∏á
# =====================================================================
try:
    from GBRT.gbrt_model import GBRTModel 
except ImportError as e:
    print(f"‚ùå Error: ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ Import ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå: {e}")
    sys.exit(1)

# =====================================================================
# 3. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•
# =====================================================================
def calculate_metrics(y_true, y_pred):
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    return rmse, mae, r2

def save_results_and_plot(gbrt_metrics, tabm_metrics, save_dir):
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)
        
    metrics_names = ['RMSE', 'MAE', 'R-squared']
    
    # --- ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå Text ---
    txt_path = os.path.join(save_dir, "model_comparison_results.txt")
    with open(txt_path, "w", encoding="utf-8") as f:
        f.write("üè† California Housing: Model Performance Comparison\n")
        f.write("="*50 + "\n\n")
        
        for name, g_val, t_val in zip(metrics_names, gbrt_metrics, tabm_metrics):
            f.write(f"Metric: {name}\n")
            f.write(f"  - GBRT (MLP): {g_val:.4f}\n")
            f.write(f"  - TabM:       {t_val:.4f}\n")
            better = "GBRT" if (g_val < t_val if name != 'R-squared' else g_val > t_val) else "TabM"
            f.write(f"  >> Winner:    {better}\n\n")

    # --- ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö ---
    x = np.arange(len(metrics_names))
    width = 0.35
    fig, ax = plt.subplots(figsize=(10, 6))
    
    rects1 = ax.bar(x - width/2, gbrt_metrics, width, label='GBRT (MLP)', color='#3498db', edgecolor='black', alpha=0.8)
    rects2 = ax.bar(x + width/2, tabm_metrics, width, label='TabM', color='#e74c3c', edgecolor='black', alpha=0.8)

    ax.set_ylabel('Scores')
    ax.set_title('Performance Comparison: GBRT(MLP) vs TabM', fontsize=14, fontweight='bold')
    ax.set_xticks(x)
    ax.set_xticklabels(metrics_names)
    ax.legend()
    ax.grid(axis='y', linestyle='--', alpha=0.7)

    ax.bar_label(rects1, padding=3, fmt='%.3f')
    ax.bar_label(rects2, padding=3, fmt='%.3f')

    fig.tight_layout()
    plt.savefig(os.path.join(save_dir, "model_comparison_plot.png"), dpi=300)
    plt.close()

# =====================================================================
# 4. Main Execution
# =====================================================================
if __name__ == "__main__":
    print(f"üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£ Evaluation (Device: {device})")

    # --- ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Case Sensitive ‡∏ï‡∏≤‡∏°‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û) ---
    data_dir = os.path.join(PROJECT_ROOT, "data", "california")
    try:
        X_test = np.load(os.path.join(data_dir, "X_num_test.npy"))
        y_test_real = np.load(os.path.join(data_dir, "Y_test.npy")).ravel()
        X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)
        print(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {X_test.shape}")
    except FileNotFoundError as e:
        print(f"‚ùå Error: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• .npy: {e}")
        sys.exit(1)

    print("-> ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î GBRT (Hybrid) Model...")
    gbrt_dir = os.path.join(PROJECT_ROOT, "GBRT")
    
    # 1. ‡πÇ‡∏´‡∏•‡∏î‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏Ç‡∏≠‡∏á MLP
    gbrt_json_path = os.path.join(gbrt_dir, "gbrt_best_params.json")
    try:
        with open(gbrt_json_path, 'r') as f:
            gbrt_params = json.load(f)
        N_LAYERS = gbrt_params["n_layers"]
        N_NEURONS = gbrt_params["n_neurons"]
        DROPOUT_RATE = gbrt_params.get("dropout_rate", 0.1)
    except FileNotFoundError:
        print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå JSON ‡∏Ç‡∏≠‡∏á GBRT ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏´‡πá‡∏ô‡∏à‡∏≤‡∏Å Error...")
        N_LAYERS, N_NEURONS, DROPOUT_RATE = 2, 504, 0.1

    # 2. ‡πÇ‡∏´‡∏•‡∏î‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (GBRT & Encoder)
    gbrt_extractor = joblib.load(os.path.join(gbrt_dir, "gbrt_extractor.joblib"))
    leaf_encoder = joblib.load(os.path.join(gbrt_dir, "leaf_encoder.joblib"))
    
    # 3. ‡πÅ‡∏õ‡∏•‡∏á‡∏£‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• X_test (8 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå -> 769 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå)
    print("   -> ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÅ‡∏õ‡∏•‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏î‡πâ‡∏ß‡∏¢ GBRT Extractor...")
    X_test_encoded = leaf_encoder.transform(gbrt_extractor.apply(X_test)).toarray()
    INPUT_DIM = X_test_encoded.shape[1] # ‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÑ‡∏î‡πâ 769
    
    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô Tensor ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤ MLP
    X_test_gbrt_tensor = torch.tensor(X_test_encoded, dtype=torch.float32).to(device)

    # 4. ‡πÇ‡∏´‡∏•‡∏î‡∏ï‡∏±‡∏ß MLP (PyTorch)
    gbrt_model = GBRTModel(
        input_dim=INPUT_DIM, 
        n_layers=N_LAYERS, 
        n_neurons=N_NEURONS,
        dropout_rate=DROPOUT_RATE
    ).to(device)
    gbrt_path = os.path.join(gbrt_dir, "mlp_gbrt_model.pt")
    gbrt_model.load_state_dict(torch.load(gbrt_path, map_location=device))
    gbrt_model.eval()

    # --- ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ TabM Model ---
    print("-> ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î TabM Model...")
    json_path = os.path.join(PROJECT_ROOT, "TabM_R2", "tabm_best_params.json")
    try:
        with open(json_path, 'r') as f:
            best_params = json.load(f)
        BEST_N_BLOCKS = best_params["n_blocks"]
        BEST_D_BLOCK = best_params["d_block"]
        BEST_DROPOUT = best_params["dropout"]
        BEST_N_BINS = best_params["n_bins"]              # <-- ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ
        BEST_D_EMBEDDING = best_params["d_embedding"]    # <-- ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ
    except FileNotFoundError:
        print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå JSON ‡∏Ç‡∏≠‡∏á TabM ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤ Default")
        BEST_N_BLOCKS, BEST_D_BLOCK, BEST_DROPOUT = 3, 256, 0.1
        BEST_N_BINS, BEST_D_EMBEDDING = 32, 16           # <-- ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡πÑ‡∏ß‡πâ

    K_ENSEMBLE = 32

    
    # ‚ö†Ô∏è ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å: ‡∏ï‡πâ‡∏≠‡∏á‡πÇ‡∏´‡∏•‡∏î X_train ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏°‡∏≤‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì bins ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ï‡∏≠‡∏ô‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏õ‡πä‡∏∞‡πÜ
    X_train_raw = np.load(os.path.join(data_dir, "X_num_train.npy"))
    X_train_tensor_for_bins = torch.tensor(X_train_raw, dtype=torch.float32)
    bins = rtdl_num_embeddings.compute_bins(X_train_tensor_for_bins, n_bins=BEST_N_BINS)
    
    ple_layer = rtdl_num_embeddings.PiecewiseLinearEmbeddings(
        bins, 
        d_embedding=BEST_D_EMBEDDING, 
        activation=torch.nn.GELU(), 
        version="A"
    )
    d_in_expanded = 8 * BEST_D_EMBEDDING

    # --- ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏°‡∏µ ple_layer ‡πÅ‡∏•‡∏∞ Flatten ---
    tabm_model = torch.nn.Sequential(
        ple_layer,
        torch.nn.Flatten(1),
        tabm.EnsembleView(k=K_ENSEMBLE),
        tabm.MLPBackboneBatchEnsemble(
            d_in=d_in_expanded,
            n_blocks=BEST_N_BLOCKS,
            d_block=BEST_D_BLOCK,
            dropout=BEST_DROPOUT,
            k=K_ENSEMBLE,
            tabm_init=True,
            scaling_init='normal',
            start_scaling_init_chunks=None,
        ),
        tabm.LinearEnsemble(BEST_D_BLOCK, 1, k=K_ENSEMBLE)
    ).to(device)

    # ‚ö†Ô∏è ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ä‡∏∑‡πà‡∏≠‡πÉ‡∏´‡∏°‡πà (tabm_model.pt) ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏ã‡∏ü‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏ó‡∏£‡∏ô
    tabm_path = os.path.join(PROJECT_ROOT, "TabM_R2", "tabm_model.pt")
    tabm_model.load_state_dict(torch.load(tabm_path, map_location=device))
    tabm_model.eval()

    print("üîÆ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå...")
    with torch.no_grad():
        # GBRT Prediction (‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á‡∏£‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô 769 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÅ‡∏•‡πâ‡∏ß)
        y_pred_gbrt = gbrt_model(X_test_gbrt_tensor).cpu().numpy().flatten()
        
        # TabM Prediction (‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö 8 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå)
        y_pred_tabm_raw = tabm_model(X_test_tensor)
        if y_pred_tabm_raw.dim() > 1 and y_pred_tabm_raw.shape[1] > 1:
            y_pred_tabm = y_pred_tabm_raw.mean(dim=1) 
        else:
            y_pred_tabm = y_pred_tabm_raw
        y_pred_tabm = y_pred_tabm.cpu().numpy().flatten()

    # --- ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å ---
    gbrt_res = calculate_metrics(y_test_real, y_pred_gbrt)
    tabm_res = calculate_metrics(y_test_real, y_pred_tabm)

    eval_dir = os.path.join(PROJECT_ROOT, "evaluation")
    save_results_and_plot(gbrt_res, tabm_res, eval_dir)

    print("\n" + "="*30)
    print(f"‚ú® ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå!")
    print(f"üìä ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ‡πÉ‡∏ô: {eval_dir}")
    print("="*30)