from skopt import forest_minimize
from skopt.space import Real, Integer
from skopt.callbacks import EarlyStopper # <-- ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ EarlyStopper
import numpy as np
from sklearn.metrics import mean_squared_error
from gbrt_model import FlexibleMLP
from pathlib import Path
import torch
import torch.nn as nn

BASE_DIR = Path(__file__).resolve().parent.parent
DATA_DIR = BASE_DIR / "data" / "california"

X_train = np.load(DATA_DIR / "X_num_train.npy")
y_train = np.load(DATA_DIR / "Y_train.npy")
X_val = np.load(DATA_DIR / "X_num_val.npy")
y_val = np.load(DATA_DIR / "Y_val.npy")

# --- ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô Tensor ‡πÄ‡∏≠‡∏≤‡πÑ‡∏ß‡πâ‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô ---
X_train_t = torch.tensor(X_train).float()
y_train_t = torch.tensor(y_train).float().view(-1, 1)
X_val_t = torch.tensor(X_val).float()
# -----------------------------------------------------------
iteration_count = 0

def objective(params):
    global iteration_count  # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ô‡∏±‡∏ö‡∏£‡∏≠‡∏ö‡∏à‡∏≤‡∏Å‡∏î‡πâ‡∏≤‡∏ô‡∏ô‡∏≠‡∏Å
    iteration_count += 1  # ‡∏ö‡∏ß‡∏Å‡πÄ‡∏û‡∏¥‡πà‡∏° 1 ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏±‡∏ô‡∏£‡∏≠‡∏ö‡πÉ‡∏´‡∏°‡πà
    n_layers, n_neurons, lr = params

    model = FlexibleMLP(n_layers=n_layers, n_neurons=n_neurons)
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    criterion = nn.MSELoss()

    model.train()
    # ‡πÄ‡∏ó‡∏£‡∏ô‡∏£‡∏≠‡∏ö‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏´‡πá‡∏ô‡∏†‡∏≤‡∏û (‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏±‡∏Å 30-50 ‡∏£‡∏≠‡∏ö‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏°‡∏±‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô‡∏´‡∏ô‡πà‡∏≠‡∏¢‡∏Å‡πá‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏±‡∏ö)
    for epoch in range(20):
        optimizer.zero_grad()
        outputs = model(X_train_t)
        loss = criterion(outputs, y_train_t)
        loss.backward()
        optimizer.step()

    model.eval()
    with torch.no_grad():
        preds = model(X_val_t).numpy()
        rmse = np.sqrt(mean_squared_error(y_val, preds))

    print(f"‚è≥ ‡∏£‡∏≠‡∏ö‡∏ó‡∏µ‡πà {iteration_count}: ‡∏•‡∏≠‡∏á‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå layers={n_layers}, neurons={n_neurons}, lr={lr:.5f} -> RMSE: {rmse:.4f}")
    return rmse

# ==========================================
# ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤: ‡∏™‡∏£‡πâ‡∏≤‡∏á Callback ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏¢‡∏∏‡∏î‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ñ‡∏∂‡∏á‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢
# ==========================================
class TargetScoreStopper(EarlyStopper):
    def __init__(self, target_score):
        self.target_score = target_score

    def _criterion(self, result):
        # ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (result.fun) ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ ‡πÉ‡∏´‡πâ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô (return True)
        if result.fun <= self.target_score:
            print(f"\nüéâ ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏à‡∏π‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏Å‡∏≥‡∏´‡∏ô‡∏î! ‡∏û‡∏ö‡∏Ñ‡πà‡∏≤ RMSE ({result.fun:.4f}) ‡∏ã‡∏∂‡πà‡∏á‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ ({self.target_score}) ‡πÅ‡∏•‡πâ‡∏ß!")
            return True
        return False

# 3. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
search_space = [
    Integer(1, 5, name='n_layers'),
    Integer(32, 256, name='n_neurons'),
    Real(1e-4, 1e-2, prior='log-uniform', name='lr')
]

# ==========================================
# 4. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≠‡∏ö
# ==========================================
MAX_CALLS = 50           # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≠‡∏ö‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏¢‡∏≠‡∏°‡πÉ‡∏´‡πâ‡∏´‡∏≤‡πÑ‡∏î‡πâ (‡πÄ‡∏ä‡πà‡∏ô 50 ‡∏£‡∏≠‡∏ö)
TARGET_RMSE = 0.65       # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô RMSE ‡∏ó‡∏µ‡πà‡∏û‡∏≠‡πÉ‡∏à (‡∏ñ‡πâ‡∏≤‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏ô‡∏µ‡πâ ‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏à‡∏∞‡∏´‡∏¢‡∏∏‡∏î‡∏ó‡∏±‡∏ô‡∏ó‡∏µ)

stopper = TargetScoreStopper(target_score=TARGET_RMSE)

print(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÉ‡∏´‡πâ GBRT ‡∏à‡∏π‡∏ô‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå... (‡∏£‡∏≠‡∏ö‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î: {MAX_CALLS}, ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ RMSE: <= {TARGET_RMSE})")
# ‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡∏ß‡πà‡∏≤‡πÄ‡∏£‡∏≤‡πÉ‡∏™‡πà callback=[stopper] ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢
result = forest_minimize(objective, search_space, n_calls=MAX_CALLS, callback=[stopper], random_state=42)

# 5. ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏à‡∏π‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à
print("\n=== ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏à‡∏π‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô ===")
print(f"‡∏Ñ‡πà‡∏≤‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (Layers, Neurons, LR): {result.x}")
print(f"‡∏Ñ‡πà‡∏≤ RMSE ‡∏ó‡∏µ‡πà‡∏ï‡πà‡∏≥‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÑ‡∏î‡πâ: {result.fun:.4f}")